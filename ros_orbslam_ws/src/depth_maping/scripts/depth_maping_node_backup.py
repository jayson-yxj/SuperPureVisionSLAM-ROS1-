import argparse
import shutil
import cv2
import matplotlib
import numpy as np
import os
import sys
import torch
import open3d as o3d
import pypose as pp
import sensor_msgs.point_cloud2 as pc2
import rospy
import std_msgs.msg
import json
import yaml

# æ·»åŠ å½“å‰è„šæœ¬ç›®å½•åˆ° Python è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
if script_dir not in sys.path:
    sys.path.insert(0, script_dir)

from depth_anything_v2.dpt import DepthAnythingV2
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

from depth_maping.msg import ImagePose
from scipy.spatial.transform import Rotation as R

from sensor_msgs.msg import PointCloud2, PointField
from std_msgs.msg import Header

from sklearn.linear_model import RANSACRegressor # ç”¨äºå¹³é¢æ‹Ÿåˆ

# ROS OccupancyGrid
from nav_msgs.msg import OccupancyGrid
from geometry_msgs.msg import Pose

'''
indoor  outdoor
'''

class Img2DepthMaping:
    def __init__(self):
        self.parser = argparse.ArgumentParser(description='Depth Anything V2 Metric Depth Estimation')
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šè¿›ä¸€æ­¥é™ä½æ·±åº¦ä¼°è®¡åˆ†è¾¨ç‡ï¼ˆ518 -> 392 -> 256ï¼‰
        self.input_size = 256  # choices=[256, 384, 512, 640]
        self.outdir = './vis_depth'
        self.encoder = 'vitb' # choices=['vits', 'vitb', 'vitl', 'vitg']
        self.load_from = "/home/sunteng/Downloads/depth_anything_v2_metric_hypersim_vitb.pth"
        self.max_depth = 70.0
        
        self.SAVE = False
        self.save_numpy = False
        self.pred_only = True
        self.grayscale = True

        # æ˜¯å¦ä¸ºç¬¬ä¸€å¸§
        self.is_first_frame = True
        # å½“å‰æ–‡ä»¶ç»å¯¹è·¯å¾„
        self.current_file_path = os.path.abspath(__file__)
        # å½“å‰æ–‡ä»¶ç›®å½•
        self.current_dir = os.path.dirname(self.current_file_path)
        
        # é‡åŠ›ä¼°è®¡ç›¸å…³
        self.last_gravity_estimate_time = 0
        self.gravity_estimate_interval = 1.0  # æ¯ç§’ä¿å­˜ä¸€æ¬¡
        self.R_align = None  # é‡åŠ›å¯¹é½çŸ©é˜µ
        self.last_R_align_load_time = 0
        self.R_align_check_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡R_alignæ›´æ–°

        # *************************************************************** #
        self.fx = 138.54264656
        self.fy = 138.60053687
        self.cx = 331.89824222
        self.cy = 239.70296783

        self.k1, self.k2, self.k3, self.k4 = -0.05094921, -0.00983458, 0.00521841, -0.00128268

        self.K = np.array([[self.fx, 0.0, self.cx],
                    [0.0, self.fy, self.cy],
                    [0.0, 0.0, 1.0]], dtype=np.float64)

        self.D = np.array([self.k1, self.k2, self.k3, self.k4], dtype=np.float64)
        self.map1, self.map2 = cv2.fisheye.initUndistortRectifyMap(self.K, self.D, np.eye(3), self.K, (640, 480), cv2.CV_16SC2)
        # ******************************************************************* #

        self.DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'
        
        self.model_configs = {
            'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},
            'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},
            'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},
            'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}
        }
        
        self.depth_anything = DepthAnythingV2(**{**self.model_configs[self.encoder], 'max_depth': self.max_depth})
        self.depth_anything.load_state_dict(torch.load(self.load_from, map_location='cpu'))
        self.depth_anything = self.depth_anything.to(self.DEVICE).eval()
        
        self.cmap = matplotlib.colormaps.get_cmap('Spectral')

        # å¹³ç§»å‘é‡çš„å°ºåº¦å€ç‡
        self.translation_size = 18

        # è£å‰ªæ·±åº¦å›¾çš„æœ€å¤§æ·±åº¦å€¼ï¼ˆå•ä½ï¼šç±³ï¼‰
        self.cut_depth = 35.0  

        self.filenames = []
        self.pose_files = []

        # *********************** ros Sub & Pub ************************* #
        self.bridge = CvBridge()
        # å¢åŠ  queue_size é¿å…æ¶ˆæ¯ä¸¢å¤±å’Œå»¶è¿Ÿç´¯ç§¯
        self.image_pose = rospy.Subscriber("/orb_slam3/image_pose",ImagePose,self.depth_solver,queue_size=100)
        
        self.rate = rospy.Rate(10)
        self.pcl_pub = rospy.Publisher('/o3d_pointCloud',PointCloud2,queue_size=10)
        
        # æ—¶é—´æˆ³è¯Šæ–­
        self.last_msg_time = None
        self.processing_times = []
        
        # å‘å¸ƒæ·±åº¦å›¾
        # self.depth_pub = rospy.Publisher('/depth_anything/depth_image', Image, queue_size=10)
        # rospy.loginfo("æ·±åº¦å›¾å‘å¸ƒå™¨å·²åˆå§‹åŒ–: /depth_anything/depth_image")

        # *********************** needed pose ******************* #
        self.now_pose = pp.SE3(torch.tensor([0., 0., 0., 0., 0., 0., 1.])) # åˆå§‹åŒ–T

        # ************************ æ»‘åŠ¨çª—å£ç‚¹äº‘åŠŸèƒ½ ********************** #
        # æ˜¯å¦å¯ç”¨æ»‘åŠ¨çª—å£æ¨¡å¼ï¼ˆåªæ˜¾ç¤ºæœ€è¿‘Nå¸§ï¼‰
        self.enable_sliding_window = rospy.get_param('~enable_sliding_window', True)
        # æ»‘åŠ¨çª—å£å¤§å°ï¼ˆä¿ç•™æœ€è¿‘Nå¸§ç‚¹äº‘ï¼‰
        self.sliding_window_size = rospy.get_param('~sliding_window_size', 3)
        # å­˜å‚¨æ¯ä¸€å¸§çš„ç‚¹äº‘
        self.point_cloud_frames = []  # åˆ—è¡¨ï¼Œå­˜å‚¨æ¯å¸§çš„ PointCloud å¯¹è±¡
        
        rospy.loginfo(f"æ»‘åŠ¨çª—å£æ¨¡å¼: {'å¯ç”¨' if self.enable_sliding_window else 'ç¦ç”¨'}")
        if self.enable_sliding_window:
            rospy.loginfo(f"æ»‘åŠ¨çª—å£å¤§å°: {self.sliding_window_size} å¸§")

        # ************************ é«˜åº¦è¿‡æ»¤åŠŸèƒ½ ********************** #
        # æ˜¯å¦å¯ç”¨é«˜åº¦è¿‡æ»¤
        self.enable_height_filter = rospy.get_param('~enable_height_filter', True)
        # é«˜åº¦è¿‡æ»¤æ¨¡å¼ï¼š'relative' æˆ– 'absolute'
        self.height_filter_mode = rospy.get_param('~height_filter_mode', 'relative')
        
        if self.height_filter_mode == 'relative':
            # ç›¸å¯¹æ¨¡å¼ï¼šä½¿ç”¨ç›¸æœºé«˜åº¦çš„ç™¾åˆ†æ¯”ï¼ˆé€‚ç”¨äºå•ç›®SLAMï¼Œå°ºåº¦ä¸ç¡®å®šï¼‰
            self.height_ratio_min = rospy.get_param('~height_ratio_min', 0.3)  # ä¿ç•™ç›¸æœºé«˜åº¦30%ä»¥ä¸Šçš„ç‚¹
            self.height_ratio_max = rospy.get_param('~height_ratio_max', 2.0)  # ä¿ç•™ç›¸æœºé«˜åº¦200%ä»¥ä¸‹çš„ç‚¹
            rospy.loginfo(f"é«˜åº¦è¿‡æ»¤: {'å¯ç”¨' if self.enable_height_filter else 'ç¦ç”¨'} (ç›¸å¯¹æ¨¡å¼)")
            if self.enable_height_filter:
                rospy.loginfo(f"é«˜åº¦æ¯”ä¾‹èŒƒå›´: [{self.height_ratio_min:.1f}x ~ {self.height_ratio_max:.1f}x] ç›¸æœºé«˜åº¦")
        else:
            # ç»å¯¹æ¨¡å¼ï¼šä½¿ç”¨å›ºå®šç±³æ•°ï¼ˆé€‚ç”¨äºå·²çŸ¥å°ºåº¦çš„åœºæ™¯ï¼‰
            self.height_min = rospy.get_param('~height_min', -2.0)
            self.height_max = rospy.get_param('~height_max', 3.0)
            rospy.loginfo(f"é«˜åº¦è¿‡æ»¤: {'å¯ç”¨' if self.enable_height_filter else 'ç¦ç”¨'} (ç»å¯¹æ¨¡å¼)")
            if self.enable_height_filter:
                rospy.loginfo(f"é«˜åº¦èŒƒå›´: [{self.height_min:.2f}m, {self.height_max:.2f}m] (Yè½´)")

        # **************** OccupancyGrid åœ°å›¾å‘å¸ƒå™¨ **************** #
        self.frame_counter = 0
        self.map_update_interval = 1           # æ¯ 5 å¸§æ›´æ–°ä¸€æ¬¡åœ°å›¾ï¼ˆå¯è°ƒï¼Œ5~20 éƒ½åˆç†ï¼‰
        self.map_pub = rospy.Publisher('/projected_map', OccupancyGrid, queue_size=1, latch=True)
        
        # 2Dåœ°å›¾é«˜åº¦è¿‡æ»¤å‚æ•°ï¼ˆç™¾åˆ†æ¯”æ¨¡å¼ï¼‰
        self.map_height_ratio_min = rospy.get_param('~map_height_ratio_min', 0.3)  # 2Dåœ°å›¾ä¿ç•™æœ€ä½30%ä»¥ä¸Š
        self.map_height_ratio_max = rospy.get_param('~map_height_ratio_max', 0.7)  # 2Dåœ°å›¾ä¿ç•™æœ€é«˜70%ä»¥ä¸‹
        
        rospy.loginfo("2D OccupancyGrid åœ°å›¾å‘å¸ƒå™¨å·²åˆå§‹åŒ–: /projected_map")
        rospy.loginfo(f"2Dåœ°å›¾é«˜åº¦è¿‡æ»¤: [{self.map_height_ratio_min:.1f} ~ {self.map_height_ratio_max:.1f}] (ç™¾åˆ†æ¯”)")


        # ************************ ç‚¹äº‘æŸ¥çœ‹å™¨ ********************** #
        # ğŸ”¥ ä¼˜åŒ–ï¼šé»˜è®¤ç¦ç”¨å¯è§†åŒ–ä»¥æå‡æ€§èƒ½
        self.enable_visualization = rospy.get_param('~enable_visualization', False)
        rospy.logwarn("âš ï¸  ä¸ºæå‡æ€§èƒ½ï¼ŒOpen3D å¯è§†åŒ–å·²é»˜è®¤ç¦ç”¨ã€‚å¦‚éœ€å¯ç”¨ï¼Œè¯·è®¾ç½® enable_visualization:=true")
        
        if self.enable_visualization:
            try:
                self.vis = o3d.visualization.VisualizerWithKeyCallback()
                self.vis.create_window(window_name="point cloud", width=1280, height=960, visible=True)
                self.all_point_cloud = o3d.geometry.PointCloud()
                self.vis.add_geometry(self.all_point_cloud)
                self.reset_view = True # æ˜¯å¦ç¬¬ä¸€å¸§
                rospy.loginfo("Open3D å¯è§†åŒ–çª—å£å·²å¯ç”¨")
            except Exception as e:
                rospy.logwarn(f"æ— æ³•åˆ›å»º Open3D å¯è§†åŒ–çª—å£: {e}")
                rospy.logwarn("å°†ç¦ç”¨å¯è§†åŒ–åŠŸèƒ½ï¼Œä»…å‘å¸ƒç‚¹äº‘è¯é¢˜")
                self.enable_visualization = False
                self.all_point_cloud = o3d.geometry.PointCloud()
                self.reset_view = True
        else:
            rospy.loginfo("Open3D å¯è§†åŒ–å·²ç¦ç”¨ï¼ˆé€šè¿‡å‚æ•°è®¾ç½®ï¼‰")
            self.all_point_cloud = o3d.geometry.PointCloud()
            self.reset_view = True

        self.points_with_color = np.array([], dtype=[('x', np.float32), ('y', np.float32), ('z', np.float32)])
        
        # æ·»åŠ å…³é—­æ ‡å¿—
        self.is_shutdown = False

    def depth_solver(self,data,is_depth_process=False):
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ­£åœ¨å…³é—­
        if self.is_shutdown or rospy.is_shutdown():
            return

        # ========== æ—¶é—´æˆ³è¯Šæ–­ ========== #
        import time
        callback_start_time = time.time()
        
        # è®¡ç®—æ¶ˆæ¯å»¶è¿Ÿ
        msg_timestamp = data.header.stamp.to_sec()
        current_time = rospy.Time.now().to_sec()
        msg_delay = current_time - msg_timestamp
        
        # è·³è¿‡å»¶è¿Ÿè¶…è¿‡ 0.1 ç§’çš„æ—§æ¶ˆæ¯
        if msg_delay > 0.1:
            rospy.logwarn_throttle(1, f"â­ï¸  è·³è¿‡æ—§æ¶ˆæ¯ï¼ˆå»¶è¿Ÿ {msg_delay:.3f}sï¼‰")
            return
        
        # è®¡ç®—æ¶ˆæ¯é—´éš”
        if self.last_msg_time is not None:
            msg_interval = msg_timestamp - self.last_msg_time
            rospy.loginfo_throttle(2, f"ğŸ“Š æ¶ˆæ¯å»¶è¿Ÿ: {msg_delay:.3f}s | æ¶ˆæ¯é—´éš”: {msg_interval:.3f}s ({1/msg_interval:.1f} Hz)")
        self.last_msg_time = msg_timestamp
        # ================================ #

        self.frame_counter += 1

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data.image, "bgr8")
        except Exception as e:
            rospy.logwarn(f"å›¾åƒè½¬æ¢å¤±è´¥: {e}")
            return

        translation = [data.pose.position.x,
                       data.pose.position.y,
                       data.pose.position.z]
        
        quaternion = [data.pose.orientation.x,
                      data.pose.orientation.y,
                      data.pose.orientation.z,
                      data.pose.orientation.w]
        
        
        '''
        ORB-SLAM3 çš„çŸ©é˜µå‘½åæ˜¯ã€Œç›®æ ‡åæ ‡ç³»â†’æºåæ ‡ç³»ã€ï¼ˆåç¼€ cw = Camera â† Worldï¼‰ï¼š
        Tcwï¼šWorld â†’ Cameraï¼ˆä¸–ç•Œåˆ°ç›¸æœºï¼‰ï¼›
        Twcï¼šCamera â†’ Worldï¼ˆç›¸æœºåˆ°ä¸–ç•Œï¼‰ï¼›
        '''
        T_pp = pp.SE3(torch.tensor(translation + quaternion)) # Tcw
        T_pp_inv = pp.Inv(T_pp) # Twc

        original_translation = T_pp_inv.translation()
        original_rotation = T_pp_inv.rotation() 

        new_translation = original_translation * self.translation_size

        T_pp_inv_new = pp.SE3(torch.cat([new_translation, original_rotation]))

        print("SE3: ",T_pp)
        print("SE3_inv: ",T_pp_inv)

        raw_image = cv2.cvtColor(cv_image.copy(), cv2.COLOR_BGR2RGB)
        undistorted_frame = cv2.remap(raw_image, self.map1, self.map2, cv2.INTER_LINEAR)
        cv2.imshow("Undistorted Frame", undistorted_frame)
        cv2.waitKey(1)
        
        # åˆå§‹åŒ– GE_information ç›®å½•
        if self.is_first_frame:
            self.is_first_frame = False
            ge_info_dir = f"{self.current_dir}/GE_information"
            if not os.path.exists(ge_info_dir):
                os.makedirs(ge_info_dir)
                rospy.loginfo(f"âœ“ åˆ›å»ºé‡åŠ›ä¼°è®¡ç›®å½•: {ge_info_dir}")
            else:
                rospy.loginfo(f"âœ“ æ¸…ç©ºé‡åŠ›ä¼°è®¡ç›®å½•: {ge_info_dir}")
                self.clear_folder(ge_info_dir)
        
        # å®šæœŸä¿å­˜å›¾åƒå’Œä½å§¿æ•°æ®ç”¨äºé‡åŠ›ä¼°è®¡
        current_time = time.time()
        if current_time - self.last_gravity_estimate_time >= self.gravity_estimate_interval:
            self.save_image_and_pose(undistorted_frame, T_pp, data.header.stamp.to_sec(), self.frame_counter)
            self.last_gravity_estimate_time = current_time
        
        # å®šæœŸæ£€æŸ¥å¹¶åŠ è½½æœ€æ–°çš„ R_align
        if current_time - self.last_R_align_load_time >= self.R_align_check_interval:
            self.load_R_align()
            self.last_R_align_load_time = current_time
        
        # æµ‹é‡æ·±åº¦ä¼°è®¡æ—¶é—´
        depth_start = time.time()
        depth = self.depth_anything.infer_image(undistorted_frame, self.input_size)
        depth_time = time.time() - depth_start
        depth_npy = depth.copy()
        
        rospy.loginfo_throttle(2, f"â±ï¸  æ·±åº¦ä¼°è®¡è€—æ—¶: {depth_time:.3f}s ({1/depth_time:.1f} FPS)")

        # æ·±åº¦å›¾é¢„å¤„ç†
        if is_depth_process:
            depth_npy = self.preprocess_depth_map(depth_npy, kernel_size=5, threshold=0.07)
        
        # å‘å¸ƒæ·±åº¦å›¾ï¼ˆä½¿ç”¨ä¸ä½å§¿ç›¸åŒçš„æ—¶é—´æˆ³ï¼‰
        # if not self.is_shutdown and not rospy.is_shutdown():
        #     try:
        #         # å°†æ·±åº¦å›¾è½¬æ¢ä¸º ROS Image æ¶ˆæ¯ï¼ˆ32ä½æµ®ç‚¹æ•°æ ¼å¼ï¼‰
        #         depth_msg = self.bridge.cv2_to_imgmsg(depth_npy, encoding="32FC1")
        #         depth_msg.header.stamp = data.header.stamp  # ä½¿ç”¨ç›¸åŒçš„æ—¶é—´æˆ³
        #         depth_msg.header.frame_id = "camera"
        #         self.depth_pub.publish(depth_msg)
        #     except Exception as e:
        #         rospy.logwarn_throttle(5, f"å‘å¸ƒæ·±åº¦å›¾å¤±è´¥: {e}")

        if True : # self.is_needed_pose(T_pp_inv_new,dis_range=2.,yaw_range=15.,pitch_range=15.)
            point_cloud = self.npy_depth_to_point_cloud_cut(depth_npy,
                                                            self.fx,
                                                            self.fy,
                                                            self.cx,
                                                            self.cy,
                                                            T_pp_inv_new,
                                                            depth_scale=1.0,
                                                            rgb_image=undistorted_frame,
                                                            img_cup_size=128,
                                                            voxel_size=1.0
                                                            )

            # ğŸ”¥ é«˜åº¦è¿‡æ»¤ï¼ˆåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­è¿‡æ»¤ Y è½´ï¼‰
            if self.enable_height_filter and len(point_cloud.points) > 0:
                points = np.asarray(point_cloud.points)
                colors = np.asarray(point_cloud.colors) if point_cloud.has_colors() else None
                
                if self.height_filter_mode == 'relative':
                    # ç›¸å¯¹æ¨¡å¼ï¼šåŸºäºç‚¹äº‘è‡ªèº«é«˜åº¦èŒƒå›´çš„ç™¾åˆ†ä½æ•°è¿‡æ»¤
                    # è®¡ç®—ç‚¹äº‘çš„é«˜åº¦èŒƒå›´
                    y_min = points[:, 1].min()
                    y_max = points[:, 1].max()
                    y_range = y_max - y_min
                    
                    if y_range < 0.01:  # é¿å…é™¤é›¶
                        rospy.logwarn_throttle(10, "ç‚¹äº‘é«˜åº¦èŒƒå›´å¤ªå°ï¼Œè·³è¿‡è¿‡æ»¤")
                        height_mask = np.ones(len(points), dtype=bool)
                    else:
                        # ratio_min=0.3 è¡¨ç¤ºè¿‡æ»¤æ‰æœ€ä½30%çš„é«˜åº¦èŒƒå›´
                        # ratio_max=0.7 è¡¨ç¤ºè¿‡æ»¤æ‰æœ€é«˜30%çš„é«˜åº¦èŒƒå›´
                        # ä¾‹å¦‚ï¼šy_range=10m, ratio_min=0.3, ratio_max=0.7
                        #   ä¿ç•™èŒƒå›´ï¼šy_min+3m åˆ° y_min+7m
                        height_min_abs = y_min + y_range * self.height_ratio_min
                        height_max_abs = y_min + y_range * self.height_ratio_max
                        
                        height_mask = (points[:, 1] >= height_min_abs) & (points[:, 1] <= height_max_abs)
                        
                        rospy.loginfo_throttle(10, f"ğŸ“ ç‚¹äº‘é«˜åº¦: [{y_min:.2f}, {y_max:.2f}] èŒƒå›´:{y_range:.2f} | è¿‡æ»¤: [{height_min_abs:.2f}, {height_max_abs:.2f}]")
                else:
                    # ç»å¯¹æ¨¡å¼ï¼šä½¿ç”¨å›ºå®šé«˜åº¦èŒƒå›´
                    height_mask = (points[:, 1] >= self.height_min) & (points[:, 1] <= self.height_max)
                
                filtered_points = points[height_mask]
                
                # åˆ›å»ºè¿‡æ»¤åçš„ç‚¹äº‘
                point_cloud = o3d.geometry.PointCloud()
                point_cloud.points = o3d.utility.Vector3dVector(filtered_points)
                
                if colors is not None:
                    filtered_colors = colors[height_mask]
                    point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)
                
                # ç»Ÿè®¡è¿‡æ»¤ä¿¡æ¯
                filtered_count = len(points) - len(filtered_points)
                if filtered_count > 0:
                    rospy.loginfo_throttle(10, f"ğŸ” é«˜åº¦è¿‡æ»¤: ç§»é™¤ {filtered_count}/{len(points)} ç‚¹ ({filtered_count/len(points)*100:.1f}%)")

            # æ ¹æ®æ»‘åŠ¨çª—å£æ¨¡å¼æ›´æ–°ç‚¹äº‘
            if self.enable_sliding_window:
                # æ»‘åŠ¨çª—å£æ¨¡å¼ï¼šåªä¿ç•™æœ€è¿‘Nå¸§
                self.point_cloud_frames.append(point_cloud)
                
                # å¦‚æœè¶…è¿‡çª—å£å¤§å°ï¼Œç§»é™¤æœ€æ—§çš„å¸§
                if len(self.point_cloud_frames) > self.sliding_window_size:
                    self.point_cloud_frames.pop(0)
                
                # åˆå¹¶å½“å‰çª—å£å†…çš„æ‰€æœ‰ç‚¹äº‘
                self.all_point_cloud = o3d.geometry.PointCloud()
                for frame_cloud in self.point_cloud_frames:
                    self.all_point_cloud += frame_cloud
                
                rospy.loginfo_throttle(5, f"æ»‘åŠ¨çª—å£: å½“å‰æ˜¾ç¤º {len(self.point_cloud_frames)}/{self.sliding_window_size} å¸§")
            else:
                # ç´¯ç§¯æ¨¡å¼ï¼šæŒç»­ç´¯åŠ æ‰€æœ‰ç‚¹äº‘
                self.all_point_cloud += point_cloud
        
        # ç‚¹äº‘å‘å¸ƒé¢‘ç‡
        if not self.is_shutdown and not rospy.is_shutdown() and self.frame_counter % 1 == 0:
            try:
                all_pointCloud_pc2 = self.o3d_to_ros_pointCloud2(self.all_point_cloud,"map")
                self.pcl_pub.publish(all_pointCloud_pc2)
            except rospy.ROSException as e:
                rospy.logwarn_throttle(5, f"å‘å¸ƒç‚¹äº‘å¤±è´¥ï¼ˆèŠ‚ç‚¹å¯èƒ½æ­£åœ¨å…³é—­ï¼‰: {e}")
            except Exception as e:
                rospy.logwarn(f"ç‚¹äº‘è½¬æ¢å¤±è´¥: {e}")

        # åœ°å›¾æ›´æ–°é¢‘ç‡
        if self.frame_counter % 1 == 0:
            occ_msg = self.project_to_2d_occupancy(
                resolution=0.8,                              # å¯è°ƒï¼š0.02~0.1
                height_ratio_min=self.map_height_ratio_min,  # ä½¿ç”¨ç™¾åˆ†æ¯”
                height_ratio_max=self.map_height_ratio_max,  # ä½¿ç”¨ç™¾åˆ†æ¯”
                occupied_thresh=3                           # ç‚¹æ•°é˜ˆå€¼ï¼Œå¯æ ¹æ®å¯†åº¦è°ƒ 3~10
            )
            if occ_msg is not None:
                self.map_pub.publish(occ_msg)
                rospy.loginfo_throttle(5, f"å·²å‘å¸ƒ2D Occåœ°å›¾ ({occ_msg.info.width}x{occ_msg.info.height}, res={occ_msg.info.resolution}m)")
        
        # æ¸²æŸ“é¢‘ç‡
        if self.enable_visualization and not self.is_shutdown and self.frame_counter % 3 == 0:
            try:
                self.vis.poll_events()
                self.vis.update_renderer()
            except Exception as e:
                rospy.logwarn_throttle(10, f"æ¸²æŸ“å¤±è´¥: {e}")
        
        # è®°å½•æ€»å¤„ç†æ—¶é—´
        callback_total_time = time.time() - callback_start_time
        self.processing_times.append(callback_total_time)
        if len(self.processing_times) > 100:
            self.processing_times.pop(0)
        
        avg_processing_time = np.mean(self.processing_times)
        rospy.loginfo_throttle(5, f"ğŸ”§ å›è°ƒæ€»è€—æ—¶: {callback_total_time:.3f}s | å¹³å‡: {avg_processing_time:.3f}s | ç†è®ºæœ€å¤§é¢‘ç‡: {1/avg_processing_time:.1f} Hz")

    def preprocess_depth_map(self,depth_map, kernel_size=3, threshold=0.05):
        """
        æ·±åº¦å›¾é¢„å¤„ç†ï¼Œå‡å°‘è¾¹ç¼˜å™ªå£°
        """
        
        # 1. ä¸­å€¼æ»¤æ³¢ï¼ˆå»é™¤æ¤’ç›å™ªå£°ï¼‰
        depth_filtered = cv2.medianBlur(depth_map.astype(np.float32), kernel_size)
        
        # 2. åŒè¾¹æ»¤æ³¢ï¼ˆä¿ç•™è¾¹ç¼˜ï¼‰
        depth_filtered = cv2.bilateralFilter(depth_filtered, d=5, sigmaColor=0.1, sigmaSpace=5)
        
        # 3. å½¢æ€å­¦æ“ä½œï¼ˆå¡«å……å°å­”æ´ï¼‰
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        depth_filtered = cv2.morphologyEx(depth_filtered, cv2.MORPH_CLOSE, kernel)
        
        # 4. æ·±åº¦ä¸€è‡´æ€§æ£€æŸ¥
        depth_gradient = np.abs(cv2.Sobel(depth_filtered, cv2.CV_64F, 1, 1, ksize=3))
        
        # 5. æ¢¯åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤è¾¹ç¼˜é«˜æ¢¯åº¦ç‚¹ï¼‰
        edge_mask = depth_gradient < threshold
        depth_filtered[~edge_mask] = 0  # å°†é«˜æ¢¯åº¦ç‚¹è®¾ä¸ºæ— æ•ˆ
        
        return depth_filtered

    def npy_depth_to_point_cloud(self,depth_map_npy, fx, fy, cx, cy, T_pp, depth_scale=1.0, rgb_image=None):
        depth_map = depth_map_npy
        valid_mask = (depth_map > 0) & (depth_map < 50) & np.isfinite(depth_map)

        hight,width = depth_map.shape
        u,v = np.meshgrid(np.arange(width), np.arange(hight))

        Z = depth_map[valid_mask] / depth_scale
        X = (u[valid_mask]-cx)*Z/fx
        Y = (v[valid_mask]-cy)*Z/fy

        points = np.stack((X, Y, Z), axis=-1).reshape(-1, 3)

        # å°†ç‚¹äº‘è½¬æ¢ä¸ºPyTorchå¼ é‡
        points_cam_tensor = torch.tensor(points, dtype=torch.float32)

        # å¯¹é½è®¡ç®—è®¾å¤‡ å¯¹åæœŸgpuä¼˜åŒ–haveå¸®åŠ©
        device = T_pp.device
        points_cam_tensor = points_cam_tensor.to(device)
        
        # ä½¿ç”¨*è¿ç®—ç¬¦è¿›è¡Œå˜æ¢ï¼ˆpyposeä¼šè‡ªåŠ¨å¤„ç†é½æ¬¡åæ ‡ï¼‰
        points_world_tensor = T_pp * points_cam_tensor
        
        # è½¬æ¢å›NumPy
        points_world = points_world_tensor.detach().cpu().numpy()

        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points_world)

        if rgb_image is not None:
            color_img = rgb_image
            color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
            if color_img.shape[:2]!= (hight, width):
                color_img = cv2.resize(color_img, (width, hight))
            colors = color_img[valid_mask].reshape(-1,3)/255.0
            pcd.colors = o3d.utility.Vector3dVector(colors)

        # é™é‡‡æ¨£
        pcd = pcd.voxel_down_sample(voxel_size=0.5)
        return pcd
    
    def npy_depth_to_point_cloud_cut(self,depth_map_npy, fx, fy, cx, cy, T_pp, depth_scale=1.0, rgb_image=None, img_cup_size=8,voxel_size=2.0):
        depth_map = depth_map_npy
        hight,width = depth_map.shape
        
        start_x, end_x = int(width/img_cup_size), int(width*(img_cup_size-1)/img_cup_size)
        start_y, end_y = int(hight/img_cup_size), int(hight*(img_cup_size-1)/img_cup_size)

        u,v = np.meshgrid(np.arange(width/img_cup_size,width*(img_cup_size-1)/img_cup_size), np.arange(hight/img_cup_size,hight*(img_cup_size-1)/img_cup_size))

        depth_cropped = depth_map[start_y:end_y, start_x:end_x]
        valid_mask = (depth_cropped > 0) & (depth_cropped < self.cut_depth) & np.isfinite(depth_cropped)
        
        Z = depth_cropped[valid_mask] / depth_scale
        X = (u[valid_mask]-cx)*Z/fx
        Y = (v[valid_mask]-cy)*Z/fy

        points = np.stack((X, Y, Z), axis=-1).reshape(-1, 3)

        # å°†ç‚¹äº‘è½¬æ¢ä¸ºPyTorchå¼ é‡
        points_cam_tensor = torch.tensor(points, dtype=torch.float32)

        # å¯¹é½è®¡ç®—è®¾å¤‡ å¯¹åæœŸgpuä¼˜åŒ–haveå¸®åŠ©
        device = T_pp.device
        points_cam_tensor = points_cam_tensor.to(device)
        
        # ä½¿ç”¨*è¿ç®—ç¬¦è¿›è¡Œå˜æ¢ï¼ˆpyposeä¼šè‡ªåŠ¨å¤„ç†é½æ¬¡åæ ‡ï¼‰
        points_world_tensor = T_pp * points_cam_tensor
        
        # è½¬æ¢å›NumPy
        points_world = points_world_tensor.detach().cpu().numpy()

        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points_world)

        if rgb_image is not None:
            color_img = rgb_image
            color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
            if color_img.shape[:2]!= (hight, width):
                color_img = cv2.resize(color_img, (width, hight))
                
            # è£å‰ª
            color_cropped = color_img[start_y:end_y, start_x:end_x]
            colors = color_cropped[valid_mask].reshape(-1,3)/255.0
            pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # é™é‡‡æ¨£
        pcd = pcd.voxel_down_sample(voxel_size=voxel_size)
       
        voxel_grid_loc = o3d.geometry.VoxelGrid.create_from_point_cloud(
            pcd,voxel_size=1
        )

        return pcd

    def is_needed_pose(self,T,dis_range=4.,yaw_range=20.,pitch_range=20.):
        now_t = self.now_pose.translation()
        now_r = self.now_pose.rotation() 
        t = T.translation()
        r = T.rotation()

        t_diff = t - now_t
        distance = torch.norm(t_diff,p=2) # L2èŒƒæ•°

        now_r_inv = now_r.Inv()
        q_diff = r*now_r_inv # è®¡ç®—ç›¸å¯¹æ—‹è½¬q  
        r = R.from_quat(q_diff)
        euler_angles_rad = r.as_euler('xyz')
        euler_angles_deg = np.degrees(euler_angles_rad)

        print(f"Roll (X): {euler_angles_deg[0]:.2f}Â°")
        print(f"Pitch (Y): {euler_angles_deg[1]:.2f}Â°")
        print(f"Yaw (Z): {euler_angles_deg[2]:.2f}Â°")

        print(f"\ndistance:{distance}\nq_diff:{q_diff}")

        if distance > dis_range or abs(euler_angles_deg[2])>yaw_range or abs(euler_angles_deg[1])>pitch_range:
            self.now_pose = T
            return True
        return False

    def o3d_to_ros_pointCloud2(self,o3d_points,image_id="odom"):
        points = np.asarray(o3d_points.points)
        R_cam_to_ros = np.array([
            [0,  0,  1],   # ROS X = Cam Z
            [-1, 0,  0],   # ROS Y = -Cam X
            [0, -1,  0]    # ROS Z = -Cam Y
        ])

        # points = points @ R_cam_to_ros.T

        # åº”ç”¨é‡åŠ›å¯¹é½çŸ©é˜µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.R_align is not None:
            points = points @ self.R_align.T

        # åˆ¤æ–­ç‚¹äº‘æœ‰æ²¡æœ‰é¢œè‰²
        if o3d_points.has_colors():
            colors = np.asarray(o3d_points.colors)*255
            colors = colors.astype(np.uint8)

            # åˆå§‹åŒ–æœ‰è‰²ç‚¹äº‘
            self.points_with_color = np.zeros(len(points),dtype=[
                ('x',np.float32),
                ('y',np.float32),
                ('z',np.float32),
                ('r',np.uint8),
                ('g',np.uint8),
                ('b',np.uint8)
            ])
            self.points_with_color['x'] = points[:,0]
            self.points_with_color['y'] = points[:,1]
            self.points_with_color['z'] = points[:,2]
            self.points_with_color['r'] = colors[:,0]
            self.points_with_color['g'] = colors[:,1]
            self.points_with_color['b'] = colors[:,2]

            # å®šä¹‰pointCloudæ¶ˆæ¯å­—æ®µï¼Ÿ
            fields = [
                PointField('x',0,PointField.FLOAT32,1),
                PointField('y',4,PointField.FLOAT32,1),
                PointField('z',8,PointField.FLOAT32,1),
                PointField('r',12,PointField.UINT8,1),
                PointField('g',13,PointField.UINT8,1),
                PointField('b',14,PointField.UINT8,1)
            ]
        
        else:
            fields = [
                PointField('x',0,PointField.FLOAT32,1),
                PointField('y',4,PointField.FLOAT32,1),
                PointField('z',8,PointField.FLOAT32,1)
            ]

        header = Header()
        header.stamp = rospy.Time.now()
        header.frame_id = image_id

        pcl_msg = pc2.create_cloud(header,fields,self.points_with_color)
        return pcl_msg
    
    def save_image_and_pose(self, image, T_pp, timestamp, frame_id):
        """
        ä¿å­˜å›¾åƒå’Œä½å§¿æ•°æ®ç”¨äºé‡åŠ›ä¼°è®¡ï¼ˆä½¿ç”¨å›ºå®šæ–‡ä»¶åï¼Œæ¯æ¬¡è¦†ç›–ï¼‰
        
        Args:
            image: å»ç•¸å˜åçš„å›¾åƒ
            T_pp: ä½å§¿ (Tcw, Camera â† World)
            timestamp: æ—¶é—´æˆ³
            frame_id: å¸§ID
        """
        try:
            ge_info_dir = f"{self.current_dir}/GE_information"
            
            # ä½¿ç”¨å›ºå®šæ–‡ä»¶åï¼ˆæ¯æ¬¡è¦†ç›–æ—§æ–‡ä»¶ï¼‰
            image_filename = "latest_img.png"
            image_path = os.path.join(ge_info_dir, image_filename)
            cv2.imwrite(image_path, image)
            
            # æå–ä½å§¿ä¿¡æ¯
            # T_pp æ˜¯ Tcw (World â†’ Camera)
            # æˆ‘ä»¬éœ€è¦ R_cw å’Œ t_cw
            R_cw = T_pp.rotation().matrix().cpu().numpy()  # 3x3
            t_cw = T_pp.translation().cpu().numpy()  # 3x1
            
            # æ„å»ºä½å§¿æ•°æ®
            pose_data = {
                'image_path': image_path,
                'timestamp': float(timestamp),
                'frame_id': int(frame_id),
                'R_cw': R_cw.tolist(),
                't_cw': t_cw.tolist()
            }
            
            # ä½¿ç”¨å›ºå®šæ–‡ä»¶åä¿å­˜ JSONï¼ˆæ¯æ¬¡è¦†ç›–ï¼‰
            pose_filename = "latest_pose.json"
            pose_path = os.path.join(ge_info_dir, pose_filename)
            with open(pose_path, 'w') as f:
                json.dump(pose_data, f, indent=2)
            
            rospy.loginfo_throttle(5, f"ğŸ’¾ å·²æ›´æ–°å›¾åƒå’Œä½å§¿: frame_{frame_id}")
            
        except Exception as e:
            rospy.logwarn(f"ä¿å­˜å›¾åƒå’Œä½å§¿å¤±è´¥: {e}")
    
    def load_R_align(self):
        """
        åŠ è½½æœ€æ–°çš„é‡åŠ›å¯¹é½çŸ©é˜µ
        """
        yaml_path = f"{self.current_dir}/GE_information/rotation_matrices.yaml"
        
        if not os.path.exists(yaml_path):
            return
        
        try:
            with open(yaml_path, 'r') as f:
                data = yaml.safe_load(f)
            
            R_align_new = np.array(data['R_align'])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
            if self.R_align is None or not np.allclose(R_align_new, self.R_align):
                self.R_align = R_align_new
                rospy.loginfo(f"âœ“ å·²åŠ è½½é‡åŠ›å¯¹é½çŸ©é˜µ (timestamp: {data.get('timestamp', 'N/A')})")
                
                # æ‰“å°å¯¹é½ä¿¡æ¯
                g_aligned = data.get('g_aligned', [0, -1, 0])
                rospy.loginfo(f"  å¯¹é½åé‡åŠ›: [{g_aligned[0]:.4f}, {g_aligned[1]:.4f}, {g_aligned[2]:.4f}]")
                
        except Exception as e:
            rospy.logwarn_throttle(10, f"åŠ è½½é‡åŠ›å¯¹é½çŸ©é˜µå¤±è´¥: {e}")


    def project_to_2d_occupancy(self,
                                resolution=0.05,
                                height_ratio_min=0.3,
                                height_ratio_max=0.7,
                                occupied_thresh=5):
        """
        å°†å½“å‰ all_point_cloud æŠ•å½±ä¸º 2D OccupancyGrid
        ä½¿ç”¨ç™¾åˆ†æ¯”æ–¹å¼è¿‡æ»¤é«˜åº¦
        """
        if len(self.all_point_cloud.points) == 0:
            rospy.logwarn_once("ç‚¹äº‘ä¸ºç©ºï¼Œè·³è¿‡ç”Ÿæˆ2Dåœ°å›¾")
            return None
        
        points = np.asarray(self.all_point_cloud.points)
        
        # ä½¿ç”¨ç™¾åˆ†æ¯”æ–¹å¼è¿‡æ»¤é«˜åº¦
        y_min = points[:, 1].min()
        y_max = points[:, 1].max()
        y_range = y_max - y_min
        
        if y_range < 0.01:
            rospy.logwarn_once("ç‚¹äº‘é«˜åº¦èŒƒå›´å¤ªå°ï¼Œä½¿ç”¨å…¨éƒ¨ç‚¹ç”Ÿæˆ2Dåœ°å›¾")
            mask = np.ones(len(points), dtype=bool)
        else:
            # è®¡ç®—ç»å¯¹é«˜åº¦èŒƒå›´
            height_min_abs = y_min + y_range * height_ratio_min
            height_max_abs = y_min + y_range * height_ratio_max
            
            mask = (points[:, 1] >= height_min_abs) & (points[:, 1] <= height_max_abs)
            
            rospy.loginfo_throttle(10, f"ğŸ—ºï¸  2Dåœ°å›¾é«˜åº¦è¿‡æ»¤: [{height_min_abs:.2f}, {height_max_abs:.2f}] (èŒƒå›´:{y_range:.2f})")
        
        points_xy = np.column_stack((points[mask, 0], points[mask, 2]))  # X, Z
        
        if len(points_xy) < 50:
            rospy.logwarn_once("é«˜åº¦èŒƒå›´å†…ç‚¹å¤ªå°‘ï¼Œè·³è¿‡ç”Ÿæˆåœ°å›¾")
            return None
        
        # è®¡ç®—åœ°å›¾è¾¹ç•Œï¼ˆåŠ 1m marginï¼‰
        x_min, y_min = points_xy.min(axis=0) - 1.0
        x_max, y_max = points_xy.max(axis=0) + 1.0
        
        width = int(np.ceil((x_max - x_min) / resolution))
        height = int(np.ceil((y_max - y_min) / resolution))
        
        # è®¡æ•°ç½‘æ ¼
        grid_counts = np.zeros((height, width), dtype=np.int16)
        
        # å‘é‡åŒ–æ˜ å°„
        ix = np.floor((points_xy[:, 0] - x_min) / resolution).astype(int)
        iy = np.floor((points_xy[:, 1] - y_min) / resolution).astype(int)
        
        valid = (ix >= 0) & (ix < width) & (iy >= 0) & (iy < height)
        ix, iy = ix[valid], iy[valid]
        np.add.at(grid_counts, (-iy, ix), 1) # æ³¨æ„ Y è½´å–å ä¸ç„¶2d occmapä¼šé¢ å€’
        
        # ç”Ÿæˆ occupancy æ•°æ®
        data = np.zeros((height, width), dtype=np.int8)
        data[grid_counts >= occupied_thresh] = 100      # occupied
        data[(grid_counts > 0) & (grid_counts < occupied_thresh)] = -1  # unknown
        # å…¶ä½™ä¸º 0 (free)
        
        # ROS OccupancyGrid è¦æ±‚ä»å·¦ä¸‹è§’å¼€å§‹ï¼ŒYè½´å‘ä¸Š â†’ ç¿»è½¬
        data = data[::-1, :]
        
        # æ„é€ æ¶ˆæ¯
        occ_msg = OccupancyGrid()
        occ_msg.header.stamp = rospy.Time.now()
        occ_msg.header.frame_id = "map"
        
        occ_msg.info.resolution = resolution
        occ_msg.info.width = width
        occ_msg.info.height = height
        occ_msg.info.origin.position.x = x_min
        occ_msg.info.origin.position.y = y_min
        occ_msg.info.origin.position.z = 0.0
        occ_msg.info.origin.orientation.w = 1.0
        
        occ_msg.data = data.flatten().tolist()
        
        return occ_msg


    def align_map_to_ground(self,point_cloud):
        """
        å°†ç‚¹äº‘å¯¹é½åˆ°åœ°é¢
        
        Args:
            point_cloud: Open3D PointCloud å¯¹è±¡
        
        Returns:
            aligned_cloud: å¯¹é½åçš„ç‚¹äº‘
            transform: å˜æ¢çŸ©é˜µ
        """
        points = np.asarray(point_cloud.points)
        
        # 1. é€‰æ‹©æœ€ä½çš„ç‚¹ä½œä¸ºåœ°é¢å€™é€‰
        y_min = np.percentile(points[:, 1], 5) 
        ground_candidates = points[points[:, 1] < y_min + 0.5]
        
        # 2. RANSAC æ‹Ÿåˆå¹³é¢
        X = ground_candidates[:, [0,2]]  # X, Z
        y = ground_candidates[:, 1]   # Y
        
        ransac = RANSACRegressor(residual_threshold=0.1)
        ransac.fit(X, y)
        
        # 3. è®¡ç®—å¹³é¢æ³•å‘é‡
        # å¹³é¢æ–¹ç¨‹: Y = a*X + b*Z + c
        # æ³•å‘é‡: (-a, -b, 1)
        a, b = ransac.estimator_.coef_
        c = ransac.estimator_.intercept_
        
        normal = np.array([-a, -b, 1])
        normal = normal / np.linalg.norm(normal)
        
        # 4. è®¡ç®—æ—‹è½¬çŸ©é˜µï¼ˆå°†æ³•å‘é‡å¯¹é½åˆ° Z è½´ï¼‰
        z_axis = np.array([0, 1, 0])
        
        # æ—‹è½¬è½´
        rotation_axis = np.cross(normal, z_axis)
        rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)
        
        # æ—‹è½¬è§’åº¦
        angle = np.arccos(np.dot(normal, z_axis))
        
        # Rodrigues æ—‹è½¬å…¬å¼
        K = np.array([
            [0, -rotation_axis[2], rotation_axis[1]],
            [rotation_axis[2], 0, -rotation_axis[0]],
            [-rotation_axis[1], rotation_axis[0], 0]
        ])
        
        R = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)
        
        # 5. åº”ç”¨å˜æ¢
        points_aligned = points @ R.T
        
        # 6. å¹³ç§»åˆ°åœ°é¢ Z=0
        z_offset = np.percentile(points_aligned[:, 2], 5)
        points_aligned[:, 2] -= z_offset
        
        # åˆ›å»ºå¯¹é½åçš„ç‚¹äº‘
        aligned_cloud = o3d.geometry.PointCloud()
        aligned_cloud.points = o3d.utility.Vector3dVector(points_aligned)
        if point_cloud.has_colors():
            aligned_cloud.colors = point_cloud.colors
        
        # æ„å»ºå®Œæ•´çš„å˜æ¢çŸ©é˜µ
        transform = np.eye(4)
        transform[:3, :3] = R
        transform[2, 3] = -z_offset
        
        return aligned_cloud, transform

    def align_to_ground(self):
        if len(np.asarray(self.all_point_cloud.points)) == 0:
            rospy.logwarn("ç‚¹äº‘ä¸ºç©ºï¼Œæ— æ³•å¯¹é½åˆ°åœ°é¢")
            return
        aligned_cloud, transform = self.align_map_to_ground(self.all_point_cloud)
        self.all_point_cloud = aligned_cloud
        rospy.loginfo("ç‚¹äº‘å·²å¯¹é½åˆ°åœ°é¢")
        
        # ä¿å­˜å˜æ¢çŸ©é˜µ
        # np.save("ground_alignment_transform.npy", transform)
        print("Ground alignment transform:\n", transform)

    def clear_folder(self,folder_path):
        """
        å¿«æ·æ¸…ç©ºæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­æ–‡ä»¶å¤¹ï¼ˆä¿ç•™æ ¹æ–‡ä»¶å¤¹ï¼‰
        :param folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
        """
        # å…ˆæ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œé¿å…æŠ¥é”™
        if not os.path.exists(folder_path):
            print(f"æ–‡ä»¶å¤¹ {folder_path} ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤")
            return
        
        # éå†å¹¶åˆ é™¤æ‰€æœ‰å†…å®¹
        for item in os.listdir(folder_path):
            item_path = os.path.join(folder_path, item)
            try:
                # å¦‚æœæ˜¯æ–‡ä»¶/é“¾æ¥ï¼Œç›´æ¥åˆ é™¤
                if os.path.isfile(item_path) or os.path.islink(item_path):
                    os.unlink(item_path)
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œé€’å½’åˆ é™¤æ•´ä¸ªæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬å†…å®¹ï¼‰
                elif os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                print(f"å·²åˆ é™¤ï¼š{item_path}")
            except Exception as e:
                print(f"åˆ é™¤å¤±è´¥ {item_path}ï¼š{e}")


if __name__ == "__main__":
    rospy.init_node("depth_maping_node")
    i2d = None
    
    try:
        i2d = Img2DepthMaping()
        rospy.loginfo("Img to maping...")
        rospy.spin()
    except KeyboardInterrupt:
        rospy.loginfo("æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­èŠ‚ç‚¹...")
    except Exception as e:
        rospy.logerr(f"èŠ‚ç‚¹è¿è¡Œå‡ºé”™: {e}")
    finally:
        # è®¾ç½®å…³é—­æ ‡å¿—
        if i2d is not None:
            i2d.is_shutdown = True
            rospy.loginfo("æ­£åœ¨ä¿å­˜æ•°æ®å¹¶æ¸…ç†èµ„æº...")
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å›è°ƒå‡½æ•°å®Œæˆ
            rospy.sleep(0.5)
            
            # ä¿å­˜ç‚¹äº‘
            try:
                output_path = os.path.join(script_dir, "pointCloud/HT_vslam.ply")
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                o3d.io.write_point_cloud(output_path, i2d.all_point_cloud)
                rospy.loginfo(f"âœ“ ç‚¹äº‘å·²ä¿å­˜åˆ°: {output_path}")
            except Exception as e:
                rospy.logwarn(f"âœ— ä¿å­˜ç‚¹äº‘å¤±è´¥: {e}")
            
            # å…³é—­å¯è§†åŒ–çª—å£
            if i2d.enable_visualization:
                try:
                    if hasattr(i2d, 'vis'):
                        i2d.vis.destroy_window()
                    rospy.loginfo("âœ“ å¯è§†åŒ–çª—å£å·²å…³é—­")
                except Exception as e:
                    rospy.logwarn(f"å…³é—­å¯è§†åŒ–çª—å£å¤±è´¥: {e}")
            
            # å…³é—­ OpenCV çª—å£
            try:
                cv2.destroyAllWindows()
            except:
                pass
            
            rospy.loginfo("èŠ‚ç‚¹å·²å®‰å…¨å…³é—­")
            # if i2d.enable_visualization:
            try:
                o3d.visualization.draw_geometries([i2d.all_point_cloud])
            except Exception as e:
                rospy.logwarn(f"æ˜¾ç¤ºæœ€ç»ˆç‚¹äº‘å¤±è´¥: {e}")